{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_vwE0hBlNYKQ"
      },
      "outputs": [],
      "source": [
        "# ! git clone https://github.com/bochendong/OCR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PmsX4UTvLOjC"
      },
      "outputs": [],
      "source": [
        "# ! pip install -q datasets seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FQpMCn9NLOjD"
      },
      "outputs": [],
      "source": [
        "# ! python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n-cSouS_LOjD"
      },
      "outputs": [],
      "source": [
        "# ! huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d7N3FGplxo9x"
      },
      "outputs": [],
      "source": [
        "# ! git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q4x2pGwrj3M",
        "outputId": "6bb5a859-d6b9-4afa-99b6-8d78c1a036f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/OCR\n"
          ]
        }
      ],
      "source": [
        "cd OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "de6oK3iPLOjE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from Code.DataSet.DataPreprocess import DataPreprocessor\n",
        "from Code.RLAgent.Agent import Q_LearningAgent\n",
        "from Code.RLAgent.Train import train_rl_agent\n",
        "from Code.RLAgent.Eval import EvalRlAgent\n",
        "from Code.Environment.Environment import Env\n",
        "from Code.Utils.GetBaseModel import getBaseModel\n",
        "from Code.Utils.Logging import SetupLogging, PlotAgentLoss\n",
        "from Code.Utils.Performance import Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ApWR9Eb6NYKR"
      },
      "outputs": [],
      "source": [
        "def main(learning_rate=1e-6, gamma=0.99, action_length = 32, epoches = 5, reward = \"normal\", slow_start = True):\n",
        "    Dir_PATH = f'./Log/action_length={action_length}_lr_{learning_rate}_reward={reward}_slow_start={slow_start}'\n",
        "\n",
        "    if (os.path.exists(Dir_PATH) == False):\n",
        "        os.mkdir(Dir_PATH)\n",
        "\n",
        "    SetupLogging(Dir_PATH + \"/log.txt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    funsd = DataPreprocessor()\n",
        "\n",
        "    train_loader, test_loader = funsd.GetDataLoader()\n",
        "\n",
        "    model = getBaseModel(funsd.id2label, funsd.label2id).to(device)\n",
        "    f1_cal = Performance(funsd.id2label)\n",
        "    env = Env(model, device)\n",
        "\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    agent = Q_LearningAgent(action_length, device, criterion,\n",
        "                            learning_rate=learning_rate, gamma = gamma, slow_start = slow_start)\n",
        "\n",
        "    train_rl_agent(agent, env, train_loader, action_length, path = Dir_PATH, epoches = epoches)\n",
        "\n",
        "    f1_score = EvalRlAgent(agent, env, test_loader, action_length, f1_cal)\n",
        "\n",
        "    return agent, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g89iSDceGMP"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f110b5112eb04161a5e2be1458face8b",
            "ea7c9a2f98ab42bab9214be9dea32fe3",
            "89b31b3c6ada4bdd8184764d3f643079",
            "15f56514be0c4ddf878417a2b5bce4ba",
            "4fe04db9d8864182a1cfda5fe58c4077",
            "c889d3bd583645eb8170ac7bd0e225c4",
            "158b8d46d99744ff861ba9b75e2d6ccd",
            "9865a44378a447dea0a9048e3e9f2de5",
            "7ea7c3a0cd4c4c12af77b44330550e0a",
            "aa591cd9321a46849f98387bb7254737",
            "4443bef88fe94250a111c8cfa783108c"
          ]
        },
        "id": "A8U3L18PeEAK",
        "outputId": "eade342f-a31c-4b64-8d50-d29c037f5c26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layoutlmv2 fine-tune processor used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layoutlmv2 fine tune model used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Policy: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with epsilon = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Running Mean RL Loss: 1747.5905559808016\n",
            "INFO - Running Mean RL Loss: 1634.5817443647538\n",
            "INFO - Running Mean RL Loss: 2057.988287790325\n",
            "INFO - Running Mean RL Loss: 1858.703258039947\n",
            "INFO - Running Mean RL Loss: 2362.0613715697496\n",
            "INFO - Running Mean RL Loss: 2910.447745187466\n",
            "INFO - Running Mean RL Loss: 2828.901080677891\n",
            "INFO - Running Mean RL Loss: 2614.169552060767\n",
            "INFO - Running Mean RL Loss: 2573.2994600459856\n",
            "INFO - Running Mean RL Loss: 2702.4442465981865\n",
            "INFO - Running Mean RL Loss: 2656.7466222245225\n",
            "INFO - Running Mean RL Loss: 2571.8293904018105\n",
            "INFO - Running Mean RL Loss: 2568.244845327284\n",
            "INFO - Running Mean RL Loss: 2720.028374245826\n",
            "INFO - Running Mean RL Loss: 2905.1959477158293\n",
            "INFO - Running Mean RL Loss: 2864.558015802587\n",
            "INFO - Running Mean RL Loss: 2796.657282167288\n",
            "INFO - Running Mean RL Loss: 2847.5150121604697\n",
            "INFO - Running Mean RL Loss: 2881.459742640791\n",
            "INFO - Running Mean RL Loss: 2835.7599311623335\n",
            "INFO - Running Mean RL Loss: 2978.4874814309233\n",
            "INFO - Running Mean RL Loss: 2990.319260376026\n",
            "INFO - Running Mean RL Loss: 2997.4128256974527\n",
            "INFO - Running Mean RL Loss: 2933.9114184398295\n",
            "INFO - Running Mean RL Loss: 2838.391045229804\n",
            "INFO - Running Mean RL Loss: 2900.773067040079\n",
            "INFO - Running Mean RL Loss: 2964.1320402268634\n",
            "INFO - Running Mean RL Loss: 2988.4689462476413\n",
            "INFO - Running Mean RL Loss: 3058.2359448752723\n",
            "INFO - Running Mean RL Loss: 3046.2964935410737\n",
            "INFO - Running Mean RL Loss: 3104.954018229616\n",
            "INFO - Running Mean RL Loss: 3058.4046259264896\n",
            "INFO - Running Mean RL Loss: 3066.13937400922\n",
            "INFO - Running Mean RL Loss: 3058.8082692602097\n",
            "INFO - Running Mean RL Loss: 3023.611262444505\n",
            "INFO - Running Mean RL Loss: 3115.380342387664\n",
            "INFO - Running Mean RL Loss: 3112.318376403445\n",
            "INFO - Running Mean RL Loss: 3065.1735973127943\n",
            "INFO - Running Mean RL Loss: 3024.7319841276294\n",
            "INFO - Running Mean RL Loss: 3012.8705925323593\n",
            "INFO - Running Mean RL Loss: 3027.50824820679\n",
            "INFO - Running Mean RL Loss: 3011.6724258167947\n",
            "INFO - Running Mean RL Loss: 3086.277298059883\n",
            "INFO - Running Mean RL Loss: 3061.617500742573\n",
            "INFO - Running Mean RL Loss: 3042.09616557004\n",
            "INFO - Running Mean RL Loss: 3005.339622219379\n",
            "INFO - Running Mean RL Loss: 2979.899389161919\n",
            "INFO - Running Mean RL Loss: 2943.568586894575\n",
            "INFO - Running Mean RL Loss: 2947.5249193012264\n",
            "INFO - Running Mean RL Loss: 2926.007939520639\n",
            "INFO - Running Mean RL Loss: 2948.804970581105\n",
            "INFO - Running Mean RL Loss: 2938.0696540732997\n",
            "INFO - Running Mean RL Loss: 2937.9027268656127\n",
            "INFO - Running Mean RL Loss: 2920.5356094984154\n",
            "INFO - Running Mean RL Loss: 2886.358772884761\n",
            "INFO - Running Mean RL Loss: 2915.5678886306655\n",
            "INFO - Running Mean RL Loss: 2918.851117374599\n",
            "INFO - Running Mean RL Loss: 2930.4576046681623\n",
            "INFO - Running Mean RL Loss: 2951.9693716955085\n",
            "INFO - Running Mean RL Loss: 2958.9028450862766\n",
            "INFO - Running Mean RL Loss: 2979.1543787577\n",
            "INFO - Running Mean RL Loss: 2958.0380054133025\n",
            "INFO - Running Mean RL Loss: 2943.128020514419\n",
            "INFO - Running Mean RL Loss: 2927.5954356669927\n",
            "INFO - Running Mean RL Loss: 2908.182517043984\n",
            "INFO - Running Mean RL Loss: 2896.82178403908\n",
            "INFO - Running Mean RL Loss: 2884.8139579885164\n",
            "INFO - Running Mean RL Loss: 2880.371307846867\n",
            "INFO - Running Mean RL Loss: 2911.0294305445664\n",
            "INFO - Running Mean RL Loss: 2902.119179232348\n",
            "INFO - Running Mean RL Loss: 2898.0792189604417\n",
            "INFO - Running Mean RL Loss: 2892.1160303167053\n",
            "INFO - Running Mean RL Loss: 2894.099031512902\n",
            "INFO - Running Mean RL Loss: 2888.82204255596\n",
            "INFO - Running Mean RL Loss: 2873.821177198175\n",
            "INFO - Running Mean RL Loss: 2852.8905763668213\n",
            "INFO - Running Mean RL Loss: 2850.982173895508\n",
            "INFO - Running Mean RL Loss: 2865.830726690133\n",
            "INFO - Running Mean RL Loss: 2904.3638323941764\n",
            "INFO - Running Mean RL Loss: 2887.874305830479\n",
            "INFO - Running Mean RL Loss: 2894.5511413240615\n",
            "INFO - Running Mean RL Loss: 2915.476271403169\n",
            "INFO - Running Mean RL Loss: 2891.375579498054\n",
            "INFO - Running Mean RL Loss: 2906.2019155396424\n",
            "INFO - Running Mean RL Loss: 2927.26373946055\n",
            "INFO - Running Mean RL Loss: 2911.213049226675\n",
            "INFO - Running Mean RL Loss: 2907.7684499803768\n",
            "INFO - Running Mean RL Loss: 2907.5098351858182\n",
            "INFO - Running Mean RL Loss: 2897.7031219339574\n",
            "INFO - Running Mean RL Loss: 2897.907599246416\n",
            "INFO - Running Mean RL Loss: 2887.7367863150967\n",
            "INFO - Running Mean RL Loss: 2879.7957812403147\n",
            "INFO - Running Mean RL Loss: 2874.919324951128\n",
            "INFO - Running Mean RL Loss: 2871.9987133180425\n",
            "INFO - Running Mean RL Loss: 2866.3151610158598\n",
            "INFO - Running Mean RL Loss: 2858.884284803102\n",
            "INFO - Running Mean RL Loss: 2896.311153597517\n",
            "INFO - Running Mean RL Loss: 2916.831965057476\n",
            "INFO - Running Mean RL Loss: 2912.529922616877\n",
            "INFO - Running Mean RL Loss: 2903.4373409660643\n",
            "INFO - Running Mean RL Loss: 2924.6289947081723\n",
            "INFO - Running Mean RL Loss: 2919.8497205513145\n",
            "INFO - Running Mean RL Loss: 2921.3711252006115\n",
            "INFO - Running Mean RL Loss: 2906.575930229148\n",
            "INFO - Running Mean RL Loss: 2889.388738528703\n",
            "INFO - Running Mean RL Loss: 2889.7672765061875\n",
            "INFO - Running Mean RL Loss: 2887.312375697474\n",
            "INFO - Running Mean RL Loss: 2878.819203860223\n",
            "INFO - Running Mean RL Loss: 2888.898352378165\n",
            "INFO - Running Mean RL Loss: 2880.6582901175784\n",
            "INFO - Running Mean RL Loss: 2881.2888699035043\n",
            "INFO - Running Mean RL Loss: 2864.482691361766\n",
            "INFO - Running Mean RL Loss: 2868.810983788681\n",
            "INFO - Running Mean RL Loss: 2869.372656225633\n",
            "INFO - Running Mean RL Loss: 2876.1259145825916\n",
            "INFO - Running Mean RL Loss: 2863.3126916725582\n",
            "INFO - Running Mean RL Loss: 2863.6236922524\n",
            "INFO - Running Mean RL Loss: 2872.29920558291\n",
            "INFO - Running Mean RL Loss: 2853.0088996380814\n",
            "INFO - Running Mean RL Loss: 2852.0213032400397\n",
            "INFO - Running Mean RL Loss: 2839.7554600604108\n",
            "INFO - Running Mean RL Loss: 2834.9013046576183\n",
            "INFO - Running Mean RL Loss: 2845.215219422427\n",
            "INFO - Running Mean RL Loss: 2839.3504425967203\n",
            "INFO - Running Mean RL Loss: 2840.0700604068875\n",
            "INFO - Running Mean RL Loss: 2839.372951767004\n",
            "INFO - Running Mean RL Loss: 2863.9962944436234\n",
            "INFO - Running Mean RL Loss: 2854.658807729345\n",
            "INFO - Running Mean RL Loss: 2863.6479749774066\n",
            "INFO - Running Mean RL Loss: 2870.633902427532\n",
            "INFO - Running Mean RL Loss: 2866.30156085675\n",
            "INFO - Running Mean RL Loss: 2863.325898445867\n",
            "INFO - Running Mean RL Loss: 2858.338038549016\n",
            "INFO - Running Mean RL Loss: 2874.2990152799907\n",
            "INFO - Running Mean RL Loss: 2866.6357157758607\n",
            "INFO - Running Mean RL Loss: 2887.427271439906\n",
            "INFO - Running Mean RL Loss: 2873.181002093812\n",
            "INFO - Running Mean RL Loss: 2879.667587492068\n",
            "INFO - Running Mean RL Loss: 2890.798856295973\n",
            "INFO - Running Mean RL Loss: 2892.028276516051\n",
            "INFO - Running Mean RL Loss: 2886.728265406048\n",
            "INFO - Running Mean RL Loss: 2883.5274486310354\n",
            "INFO - Running Mean RL Loss: 2902.232118268158\n",
            "INFO - Running Mean RL Loss: 2917.5311749460457\n",
            "INFO - Running Mean RL Loss: 2927.400850982026\n",
            "INFO - Running Mean RL Loss: 2926.2954051405927\n",
            "INFO - Running Mean RL Loss: 2916.66473420072\n",
            "INFO - Running Mean RL Loss: 2928.1462812451523\n",
            "INFO - Running Mean RL Loss: 2920.612500236576\n",
            "INFO - Policy: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with epsilon = 0.8615048875706075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Running Mean RL Loss: 2920.6377486340334\n",
            "INFO - Running Mean RL Loss: 2929.4001282030313\n",
            "INFO - Running Mean RL Loss: 2927.903012589479\n",
            "INFO - Running Mean RL Loss: 2917.35905712529\n",
            "INFO - Running Mean RL Loss: 2932.003244467589\n",
            "INFO - Running Mean RL Loss: 2931.2745584949985\n",
            "INFO - Running Mean RL Loss: 2941.4791372165882\n",
            "INFO - Running Mean RL Loss: 2940.759577939884\n",
            "INFO - Running Mean RL Loss: 2941.3454733693607\n",
            "INFO - Running Mean RL Loss: 2945.753559406136\n",
            "INFO - Running Mean RL Loss: 2935.8472650815715\n",
            "INFO - Running Mean RL Loss: 2926.110666720782\n",
            "INFO - Running Mean RL Loss: 2921.052501141908\n",
            "INFO - Running Mean RL Loss: 2938.154232056021\n",
            "INFO - Running Mean RL Loss: 2943.3710064491147\n",
            "INFO - Running Mean RL Loss: 2942.1221967657616\n",
            "INFO - Running Mean RL Loss: 2951.3065912646102\n",
            "INFO - Running Mean RL Loss: 2949.311455680513\n",
            "INFO - Running Mean RL Loss: 2945.7775703651614\n",
            "INFO - Running Mean RL Loss: 2935.580600497617\n",
            "INFO - Running Mean RL Loss: 2939.5263575730746\n",
            "INFO - Running Mean RL Loss: 2931.92205305561\n",
            "INFO - Running Mean RL Loss: 2926.001023279634\n",
            "INFO - Running Mean RL Loss: 2917.1890789488707\n",
            "INFO - Running Mean RL Loss: 2912.7774769535094\n",
            "INFO - Running Mean RL Loss: 2929.9206719459976\n",
            "INFO - Running Mean RL Loss: 2936.051997358335\n",
            "INFO - Running Mean RL Loss: 2936.94428867941\n",
            "INFO - Running Mean RL Loss: 2933.8409421794267\n",
            "INFO - Running Mean RL Loss: 2949.4096060295174\n",
            "INFO - Running Mean RL Loss: 2953.424595355456\n",
            "INFO - Running Mean RL Loss: 2947.072570006619\n",
            "INFO - Running Mean RL Loss: 2949.9102634778824\n",
            "INFO - Running Mean RL Loss: 2943.248607361222\n",
            "INFO - Running Mean RL Loss: 2953.6228632743523\n",
            "INFO - Running Mean RL Loss: 2951.306090629082\n",
            "INFO - Running Mean RL Loss: 2946.1944148798675\n",
            "INFO - Running Mean RL Loss: 2949.983307515357\n",
            "INFO - Running Mean RL Loss: 2951.8861486311553\n",
            "INFO - Running Mean RL Loss: 2946.6402129965118\n",
            "INFO - Running Mean RL Loss: 2947.0802995774097\n",
            "INFO - Running Mean RL Loss: 2936.235171693956\n",
            "INFO - Running Mean RL Loss: 2929.974737463401\n",
            "INFO - Running Mean RL Loss: 2934.916871395791\n",
            "INFO - Running Mean RL Loss: 2937.587977668884\n",
            "INFO - Running Mean RL Loss: 2935.7366741064448\n",
            "INFO - Running Mean RL Loss: 2930.8377367563494\n",
            "INFO - Running Mean RL Loss: 2924.8694030506344\n",
            "INFO - Running Mean RL Loss: 2918.2914434544955\n",
            "INFO - Running Mean RL Loss: 2927.362346000107\n",
            "INFO - Running Mean RL Loss: 2920.2433152088647\n",
            "INFO - Running Mean RL Loss: 2912.1561683690975\n",
            "INFO - Running Mean RL Loss: 2910.0637174684625\n",
            "INFO - Running Mean RL Loss: 2911.626210697468\n",
            "INFO - Running Mean RL Loss: 2923.1559945729123\n",
            "INFO - Running Mean RL Loss: 2920.9376776412114\n",
            "INFO - Running Mean RL Loss: 2916.9664917805585\n",
            "INFO - Running Mean RL Loss: 2914.47469767739\n",
            "INFO - Running Mean RL Loss: 2908.788539090454\n",
            "INFO - Running Mean RL Loss: 2913.078299932735\n",
            "INFO - Running Mean RL Loss: 2916.8757090789404\n",
            "INFO - Running Mean RL Loss: 2910.290329227763\n",
            "INFO - Running Mean RL Loss: 2914.8211843925624\n",
            "INFO - Running Mean RL Loss: 2929.0287864861334\n",
            "INFO - Running Mean RL Loss: 2923.189064570159\n",
            "INFO - Running Mean RL Loss: 2924.122592854842\n",
            "INFO - Running Mean RL Loss: 2916.1900453412372\n",
            "INFO - Running Mean RL Loss: 2916.415905538011\n",
            "INFO - Running Mean RL Loss: 2907.096089279267\n",
            "INFO - Running Mean RL Loss: 2911.335577757277\n",
            "INFO - Running Mean RL Loss: 2906.688987276454\n",
            "INFO - Running Mean RL Loss: 2906.396262432508\n",
            "INFO - Running Mean RL Loss: 2900.3496611868622\n",
            "INFO - Running Mean RL Loss: 2899.459897400227\n",
            "INFO - Running Mean RL Loss: 2895.4723360281127\n",
            "INFO - Running Mean RL Loss: 2892.4078333288603\n",
            "INFO - Running Mean RL Loss: 2891.0570071731345\n",
            "INFO - Running Mean RL Loss: 2891.4255087864653\n",
            "INFO - Running Mean RL Loss: 2890.6247398995415\n",
            "INFO - Running Mean RL Loss: 2902.8411496455938\n",
            "INFO - Running Mean RL Loss: 2900.3860631447374\n",
            "INFO - Running Mean RL Loss: 2907.5002282354017\n",
            "INFO - Running Mean RL Loss: 2914.142681947099\n",
            "INFO - Running Mean RL Loss: 2909.4514658404\n",
            "INFO - Running Mean RL Loss: 2907.5527726349655\n",
            "INFO - Running Mean RL Loss: 2916.439140754455\n",
            "INFO - Running Mean RL Loss: 2908.1600059513758\n",
            "INFO - Running Mean RL Loss: 2904.8217413019715\n",
            "INFO - Running Mean RL Loss: 2911.587753976762\n",
            "INFO - Running Mean RL Loss: 2907.1721154934953\n",
            "INFO - Running Mean RL Loss: 2904.141140734767\n",
            "INFO - Running Mean RL Loss: 2894.0576098470683\n",
            "INFO - Running Mean RL Loss: 2895.615713370053\n",
            "INFO - Running Mean RL Loss: 2892.701641845403\n",
            "INFO - Running Mean RL Loss: 2892.785788907484\n",
            "INFO - Running Mean RL Loss: 2888.4145425909765\n",
            "INFO - Running Mean RL Loss: 2891.303178730547\n",
            "INFO - Running Mean RL Loss: 2888.879198299507\n",
            "INFO - Running Mean RL Loss: 2897.941389661002\n",
            "INFO - Running Mean RL Loss: 2907.3367102567054\n",
            "INFO - Running Mean RL Loss: 2917.531260706802\n",
            "INFO - Running Mean RL Loss: 2916.0448154617316\n",
            "INFO - Running Mean RL Loss: 2910.087690519869\n",
            "INFO - Running Mean RL Loss: 2913.073576161179\n",
            "INFO - Running Mean RL Loss: 2921.260048876483\n",
            "INFO - Running Mean RL Loss: 2919.7425898870447\n",
            "INFO - Running Mean RL Loss: 2915.72471681408\n",
            "INFO - Running Mean RL Loss: 2909.480191755266\n",
            "INFO - Running Mean RL Loss: 2922.423310944671\n",
            "INFO - Running Mean RL Loss: 2916.305279950771\n",
            "INFO - Running Mean RL Loss: 2916.900816200492\n",
            "INFO - Running Mean RL Loss: 2912.9676225970893\n",
            "INFO - Running Mean RL Loss: 2918.001273628514\n",
            "INFO - Running Mean RL Loss: 2921.8026510102472\n",
            "INFO - Running Mean RL Loss: 2912.913753970116\n",
            "INFO - Running Mean RL Loss: 2914.86769448118\n",
            "INFO - Running Mean RL Loss: 2913.658366981662\n",
            "INFO - Running Mean RL Loss: 2911.618944395441\n",
            "INFO - Running Mean RL Loss: 2910.037335584617\n",
            "INFO - Running Mean RL Loss: 2913.458165004311\n",
            "INFO - Running Mean RL Loss: 2910.17667700258\n",
            "INFO - Running Mean RL Loss: 2908.32532926825\n",
            "INFO - Running Mean RL Loss: 2906.3826156087125\n",
            "INFO - Running Mean RL Loss: 2898.9535155449175\n",
            "INFO - Running Mean RL Loss: 2895.2198679961116\n",
            "INFO - Running Mean RL Loss: 2893.340914018535\n",
            "INFO - Running Mean RL Loss: 2894.284859341871\n",
            "INFO - Running Mean RL Loss: 2893.0170069127275\n",
            "INFO - Running Mean RL Loss: 2889.8838614799974\n",
            "INFO - Running Mean RL Loss: 2884.698526185792\n",
            "INFO - Running Mean RL Loss: 2900.7833485138785\n",
            "INFO - Running Mean RL Loss: 2898.8825352094136\n",
            "INFO - Running Mean RL Loss: 2893.108969383034\n",
            "INFO - Running Mean RL Loss: 2894.5507568523713\n",
            "INFO - Running Mean RL Loss: 2899.3308915316807\n",
            "INFO - Running Mean RL Loss: 2895.0389488160463\n",
            "INFO - Running Mean RL Loss: 2900.779229191098\n",
            "INFO - Running Mean RL Loss: 2904.099247968873\n",
            "INFO - Running Mean RL Loss: 2901.5023324097892\n",
            "INFO - Running Mean RL Loss: 2895.7362857441353\n",
            "INFO - Running Mean RL Loss: 2896.3236099235346\n",
            "INFO - Running Mean RL Loss: 2889.2611426410776\n",
            "INFO - Running Mean RL Loss: 2886.102469069962\n",
            "INFO - Running Mean RL Loss: 2880.741980770039\n",
            "INFO - Running Mean RL Loss: 2880.9271258527756\n",
            "INFO - Running Mean RL Loss: 2888.3489475036376\n",
            "INFO - Running Mean RL Loss: 2888.917082991406\n",
            "INFO - Running Mean RL Loss: 2883.614938583782\n",
            "INFO - Running Mean RL Loss: 2885.069155987927\n",
            "INFO - Policy: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with epsilon = 0.7421906713080445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Running Mean RL Loss: 2883.0634623830915\n",
            "INFO - Running Mean RL Loss: 2896.800335041303\n",
            "INFO - Running Mean RL Loss: 2895.915564571279\n",
            "INFO - Running Mean RL Loss: 2902.239192300554\n",
            "INFO - Running Mean RL Loss: 2903.939976568396\n",
            "INFO - Running Mean RL Loss: 2907.146026261677\n",
            "INFO - Running Mean RL Loss: 2906.1297354895933\n",
            "INFO - Running Mean RL Loss: 2911.897415892292\n",
            "INFO - Running Mean RL Loss: 2915.822243838487\n",
            "INFO - Running Mean RL Loss: 2923.955040511171\n",
            "INFO - Running Mean RL Loss: 2919.4739435723745\n",
            "INFO - Running Mean RL Loss: 2920.4753533626913\n",
            "INFO - Running Mean RL Loss: 2919.871125671693\n",
            "INFO - Running Mean RL Loss: 2914.69302006391\n",
            "INFO - Running Mean RL Loss: 2910.169272682672\n",
            "INFO - Running Mean RL Loss: 2907.1701291925697\n",
            "INFO - Running Mean RL Loss: 2904.7269662456297\n",
            "INFO - Running Mean RL Loss: 2901.8852296981268\n",
            "INFO - Running Mean RL Loss: 2898.993694356793\n",
            "INFO - Running Mean RL Loss: 2893.7776204738307\n",
            "INFO - Running Mean RL Loss: 2888.8796493110626\n",
            "INFO - Running Mean RL Loss: 2886.386508808072\n",
            "INFO - Running Mean RL Loss: 2889.0393625872894\n",
            "INFO - Running Mean RL Loss: 2885.1862103084836\n",
            "INFO - Running Mean RL Loss: 2885.418257804369\n",
            "INFO - Running Mean RL Loss: 2884.4508598742636\n",
            "INFO - Running Mean RL Loss: 2880.5989765356203\n",
            "INFO - Running Mean RL Loss: 2878.9534249772764\n",
            "INFO - Running Mean RL Loss: 2872.3793462014332\n",
            "INFO - Running Mean RL Loss: 2873.0119108445297\n",
            "INFO - Running Mean RL Loss: 2875.650862608754\n",
            "INFO - Running Mean RL Loss: 2873.111235375006\n",
            "INFO - Running Mean RL Loss: 2870.42097903255\n",
            "INFO - Running Mean RL Loss: 2868.6763798047527\n",
            "INFO - Running Mean RL Loss: 2866.7755831114023\n",
            "INFO - Running Mean RL Loss: 2859.8425634852633\n",
            "INFO - Running Mean RL Loss: 2855.1602419002897\n",
            "INFO - Running Mean RL Loss: 2851.2620488252833\n",
            "INFO - Running Mean RL Loss: 2850.4354366524094\n",
            "INFO - Running Mean RL Loss: 2847.9723963703264\n",
            "INFO - Running Mean RL Loss: 2844.227195131551\n",
            "INFO - Running Mean RL Loss: 2842.576534380991\n",
            "INFO - Running Mean RL Loss: 2840.480188178839\n",
            "INFO - Running Mean RL Loss: 2838.708318807792\n",
            "INFO - Running Mean RL Loss: 2838.0539928013263\n",
            "INFO - Running Mean RL Loss: 2839.685192838143\n",
            "INFO - Running Mean RL Loss: 2841.573817756421\n",
            "INFO - Running Mean RL Loss: 2838.6011195629912\n",
            "INFO - Running Mean RL Loss: 2836.3113221739704\n",
            "INFO - Running Mean RL Loss: 2831.4531078689447\n",
            "INFO - Running Mean RL Loss: 2835.461610391716\n",
            "INFO - Running Mean RL Loss: 2844.83544099963\n",
            "INFO - Running Mean RL Loss: 2840.4322487000322\n",
            "INFO - Running Mean RL Loss: 2839.659863396414\n",
            "INFO - Running Mean RL Loss: 2843.637369490842\n",
            "INFO - Running Mean RL Loss: 2846.317114057034\n",
            "INFO - Running Mean RL Loss: 2847.0202011576253\n",
            "INFO - Running Mean RL Loss: 2844.6400622049323\n",
            "INFO - Running Mean RL Loss: 2839.0465424825743\n",
            "INFO - Running Mean RL Loss: 2835.8857069494834\n",
            "INFO - Running Mean RL Loss: 2835.0188877379624\n",
            "INFO - Running Mean RL Loss: 2841.2117222959478\n",
            "INFO - Running Mean RL Loss: 2841.9061152997774\n",
            "INFO - Running Mean RL Loss: 2846.8822317997115\n",
            "INFO - Running Mean RL Loss: 2843.176382389464\n",
            "INFO - Running Mean RL Loss: 2849.6444557668187\n",
            "INFO - Running Mean RL Loss: 2855.496089937989\n",
            "INFO - Running Mean RL Loss: 2859.2924941716265\n",
            "INFO - Running Mean RL Loss: 2858.2131262896073\n",
            "INFO - Running Mean RL Loss: 2855.5648890101456\n",
            "INFO - Running Mean RL Loss: 2851.6214853117135\n",
            "INFO - Running Mean RL Loss: 2851.4400201958088\n",
            "INFO - Running Mean RL Loss: 2855.814868152675\n",
            "INFO - Running Mean RL Loss: 2853.503323888918\n",
            "INFO - Running Mean RL Loss: 2848.1895685495756\n",
            "INFO - Running Mean RL Loss: 2844.27847496371\n",
            "INFO - Running Mean RL Loss: 2841.425247279228\n",
            "INFO - Running Mean RL Loss: 2840.2408019546037\n",
            "INFO - Running Mean RL Loss: 2838.909338546608\n",
            "INFO - Running Mean RL Loss: 2839.116210022521\n",
            "INFO - Running Mean RL Loss: 2838.418174783185\n",
            "INFO - Running Mean RL Loss: 2837.4526247665094\n",
            "INFO - Running Mean RL Loss: 2837.4941589432674\n",
            "INFO - Running Mean RL Loss: 2834.3989719035117\n",
            "INFO - Running Mean RL Loss: 2835.7393102903757\n",
            "INFO - Running Mean RL Loss: 2836.837365355695\n",
            "INFO - Running Mean RL Loss: 2843.0527526750802\n",
            "INFO - Running Mean RL Loss: 2839.0265881947603\n",
            "INFO - Running Mean RL Loss: 2838.1099775565267\n",
            "INFO - Running Mean RL Loss: 2837.1982080291655\n",
            "INFO - Running Mean RL Loss: 2837.552163761645\n",
            "INFO - Running Mean RL Loss: 2841.635173606423\n",
            "INFO - Running Mean RL Loss: 2842.8471455470512\n",
            "INFO - Running Mean RL Loss: 2840.719261141556\n",
            "INFO - Running Mean RL Loss: 2843.495756226955\n",
            "INFO - Running Mean RL Loss: 2847.196415826442\n",
            "INFO - Running Mean RL Loss: 2845.563906652952\n",
            "INFO - Running Mean RL Loss: 2849.8790081095804\n",
            "INFO - Running Mean RL Loss: 2853.502016712678\n",
            "INFO - Running Mean RL Loss: 2856.750956847314\n",
            "INFO - Running Mean RL Loss: 2861.8715400049896\n",
            "INFO - Running Mean RL Loss: 2861.827632124126\n",
            "INFO - Running Mean RL Loss: 2860.2109146715466\n",
            "INFO - Running Mean RL Loss: 2861.624403402186\n",
            "INFO - Running Mean RL Loss: 2862.3323931739374\n",
            "INFO - Running Mean RL Loss: 2867.8196151917064\n",
            "INFO - Running Mean RL Loss: 2868.770276043505\n",
            "INFO - Running Mean RL Loss: 2868.1047776393766\n",
            "INFO - Running Mean RL Loss: 2869.4985343037943\n",
            "INFO - Running Mean RL Loss: 2867.648464730681\n",
            "INFO - Running Mean RL Loss: 2863.912043558922\n",
            "INFO - Running Mean RL Loss: 2863.9163026771043\n",
            "INFO - Running Mean RL Loss: 2861.5581690978515\n",
            "INFO - Running Mean RL Loss: 2865.299464906124\n",
            "INFO - Running Mean RL Loss: 2865.19899234404\n",
            "INFO - Running Mean RL Loss: 2864.478495145243\n",
            "INFO - Running Mean RL Loss: 2859.498767983105\n",
            "INFO - Running Mean RL Loss: 2858.8679052530806\n",
            "INFO - Running Mean RL Loss: 2858.078722381106\n",
            "INFO - Running Mean RL Loss: 2852.2411995963266\n",
            "INFO - Running Mean RL Loss: 2849.4947750622096\n",
            "INFO - Running Mean RL Loss: 2851.3192657970435\n",
            "INFO - Running Mean RL Loss: 2852.0262097670616\n",
            "INFO - Running Mean RL Loss: 2852.170384163202\n",
            "INFO - Running Mean RL Loss: 2848.3729390130356\n",
            "INFO - Running Mean RL Loss: 2848.963770066673\n",
            "INFO - Running Mean RL Loss: 2845.255477015853\n",
            "INFO - Running Mean RL Loss: 2846.5122937343117\n",
            "INFO - Running Mean RL Loss: 2846.690084265466\n",
            "INFO - Running Mean RL Loss: 2843.6321510923453\n",
            "INFO - Running Mean RL Loss: 2839.1748971634674\n",
            "INFO - Running Mean RL Loss: 2846.344650695477\n",
            "INFO - Running Mean RL Loss: 2842.706007391408\n",
            "INFO - Running Mean RL Loss: 2847.9813518157603\n",
            "INFO - Running Mean RL Loss: 2844.378464503503\n",
            "INFO - Running Mean RL Loss: 2842.70806535935\n",
            "INFO - Running Mean RL Loss: 2840.659285734503\n",
            "INFO - Running Mean RL Loss: 2838.262518799498\n",
            "INFO - Running Mean RL Loss: 2833.449489410363\n",
            "INFO - Running Mean RL Loss: 2833.70607033847\n",
            "INFO - Running Mean RL Loss: 2836.133284642644\n",
            "INFO - Running Mean RL Loss: 2836.9480324301703\n",
            "INFO - Running Mean RL Loss: 2838.4264100942546\n",
            "INFO - Running Mean RL Loss: 2842.3519314911814\n",
            "INFO - Running Mean RL Loss: 2838.9356832439325\n",
            "INFO - Running Mean RL Loss: 2841.9483991719817\n",
            "INFO - Running Mean RL Loss: 2839.5685642946232\n",
            "INFO - Running Mean RL Loss: 2839.025511927679\n",
            "INFO - Running Mean RL Loss: 2837.061285998082\n",
            "INFO - Policy: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with epsilon = 0.6394008908411897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Running Mean RL Loss: 2835.3293609257394\n",
            "INFO - Running Mean RL Loss: 2835.989471900537\n",
            "INFO - Running Mean RL Loss: 2836.382071005827\n",
            "INFO - Running Mean RL Loss: 2836.0148449461553\n",
            "INFO - Running Mean RL Loss: 2839.403336225569\n",
            "INFO - Running Mean RL Loss: 2839.2744713456364\n",
            "INFO - Running Mean RL Loss: 2839.3089334981973\n",
            "INFO - Running Mean RL Loss: 2835.960535806058\n",
            "INFO - Running Mean RL Loss: 2832.3691653200995\n",
            "INFO - Running Mean RL Loss: 2832.7345470936807\n",
            "INFO - Running Mean RL Loss: 2833.730866924342\n",
            "INFO - Running Mean RL Loss: 2839.322288790875\n",
            "INFO - Running Mean RL Loss: 2843.5672155046095\n",
            "INFO - Running Mean RL Loss: 2841.674782419976\n",
            "INFO - Running Mean RL Loss: 2840.3252863383536\n",
            "INFO - Running Mean RL Loss: 2841.701460866211\n",
            "INFO - Running Mean RL Loss: 2842.468755910924\n",
            "INFO - Running Mean RL Loss: 2842.0003169754705\n",
            "INFO - Running Mean RL Loss: 2843.697345502751\n",
            "INFO - Running Mean RL Loss: 2841.259970545518\n",
            "INFO - Running Mean RL Loss: 2841.782713790474\n",
            "INFO - Running Mean RL Loss: 2841.088781609245\n",
            "INFO - Running Mean RL Loss: 2844.784510299884\n",
            "INFO - Running Mean RL Loss: 2842.7252764665814\n",
            "INFO - Running Mean RL Loss: 2839.1444959114247\n",
            "INFO - Running Mean RL Loss: 2836.6823513549016\n",
            "INFO - Running Mean RL Loss: 2835.5545052865036\n",
            "INFO - Running Mean RL Loss: 2834.8917555101384\n",
            "INFO - Running Mean RL Loss: 2831.795020895479\n",
            "INFO - Running Mean RL Loss: 2833.3066421489934\n",
            "INFO - Running Mean RL Loss: 2830.143020781464\n",
            "INFO - Running Mean RL Loss: 2832.58250374584\n",
            "INFO - Running Mean RL Loss: 2829.23922022695\n",
            "INFO - Running Mean RL Loss: 2830.438802516816\n",
            "INFO - Running Mean RL Loss: 2830.4376323809306\n",
            "INFO - Running Mean RL Loss: 2828.9304541017414\n",
            "INFO - Running Mean RL Loss: 2827.6005144264504\n",
            "INFO - Running Mean RL Loss: 2828.4187119335097\n",
            "INFO - Running Mean RL Loss: 2826.9112707838144\n",
            "INFO - Running Mean RL Loss: 2828.2573492517745\n",
            "INFO - Running Mean RL Loss: 2825.306688782983\n",
            "INFO - Running Mean RL Loss: 2821.76844026583\n",
            "INFO - Running Mean RL Loss: 2823.821167710995\n",
            "INFO - Running Mean RL Loss: 2825.77613747142\n",
            "INFO - Running Mean RL Loss: 2830.4938237517704\n",
            "INFO - Running Mean RL Loss: 2830.0516663834455\n",
            "INFO - Running Mean RL Loss: 2830.7990924526534\n",
            "INFO - Running Mean RL Loss: 2829.397204137124\n",
            "INFO - Running Mean RL Loss: 2828.0329453302334\n",
            "INFO - Running Mean RL Loss: 2824.483631837559\n",
            "INFO - Running Mean RL Loss: 2822.168130789514\n",
            "INFO - Running Mean RL Loss: 2828.856000782527\n",
            "INFO - Running Mean RL Loss: 2826.739550019537\n",
            "INFO - Running Mean RL Loss: 2829.3101711880145\n",
            "INFO - Running Mean RL Loss: 2833.5871202621297\n",
            "INFO - Running Mean RL Loss: 2835.5823206140485\n",
            "INFO - Running Mean RL Loss: 2834.631231928627\n",
            "INFO - Running Mean RL Loss: 2832.0813225337906\n",
            "INFO - Running Mean RL Loss: 2828.2632377571417\n",
            "INFO - Running Mean RL Loss: 2829.213314928591\n",
            "INFO - Running Mean RL Loss: 2829.393649458745\n",
            "INFO - Running Mean RL Loss: 2825.949523889164\n",
            "INFO - Running Mean RL Loss: 2825.436358684357\n",
            "INFO - Running Mean RL Loss: 2824.6509509805687\n",
            "INFO - Running Mean RL Loss: 2820.81722549439\n",
            "INFO - Running Mean RL Loss: 2818.6872544347875\n",
            "INFO - Running Mean RL Loss: 2818.2633938298077\n",
            "INFO - Running Mean RL Loss: 2820.291921720292\n",
            "INFO - Running Mean RL Loss: 2820.0472643722505\n",
            "INFO - Running Mean RL Loss: 2818.8700606659645\n",
            "INFO - Running Mean RL Loss: 2817.1252167974358\n",
            "INFO - Running Mean RL Loss: 2815.8858010340905\n",
            "INFO - Running Mean RL Loss: 2813.2802275254016\n",
            "INFO - Running Mean RL Loss: 2810.6891678686516\n",
            "INFO - Running Mean RL Loss: 2813.5767438259327\n",
            "INFO - Running Mean RL Loss: 2812.4147486780785\n",
            "INFO - Running Mean RL Loss: 2816.0059817899532\n",
            "INFO - Running Mean RL Loss: 2818.751961632544\n",
            "INFO - Running Mean RL Loss: 2818.9930033602577\n",
            "INFO - Running Mean RL Loss: 2815.7581456222692\n",
            "INFO - Running Mean RL Loss: 2814.9548916548756\n",
            "INFO - Running Mean RL Loss: 2813.398409941096\n",
            "INFO - Running Mean RL Loss: 2810.517706200401\n",
            "INFO - Running Mean RL Loss: 2808.032782593666\n",
            "INFO - Running Mean RL Loss: 2813.9602793435984\n",
            "INFO - Running Mean RL Loss: 2814.328277122383\n",
            "INFO - Running Mean RL Loss: 2812.2847704413985\n",
            "INFO - Running Mean RL Loss: 2816.0464616104728\n",
            "INFO - Running Mean RL Loss: 2816.1550116801955\n",
            "INFO - Running Mean RL Loss: 2818.0843115991365\n",
            "INFO - Running Mean RL Loss: 2819.085296967195\n",
            "INFO - Running Mean RL Loss: 2816.586864165208\n",
            "INFO - Running Mean RL Loss: 2812.4624906319505\n",
            "INFO - Running Mean RL Loss: 2813.1449127190585\n",
            "INFO - Running Mean RL Loss: 2815.8064065806025\n",
            "INFO - Running Mean RL Loss: 2816.0885692847787\n",
            "INFO - Running Mean RL Loss: 2815.073043033243\n",
            "INFO - Running Mean RL Loss: 2816.5623166702876\n",
            "INFO - Running Mean RL Loss: 2815.811175014058\n",
            "INFO - Running Mean RL Loss: 2815.013792033242\n",
            "INFO - Running Mean RL Loss: 2814.0602769083703\n",
            "INFO - Running Mean RL Loss: 2813.2497649875904\n",
            "INFO - Running Mean RL Loss: 2814.622048307585\n",
            "INFO - Running Mean RL Loss: 2814.3781200192216\n",
            "INFO - Running Mean RL Loss: 2815.0775271840876\n",
            "INFO - Running Mean RL Loss: 2817.16278346818\n",
            "INFO - Running Mean RL Loss: 2817.163716911383\n",
            "INFO - Running Mean RL Loss: 2818.577773448342\n",
            "INFO - Running Mean RL Loss: 2817.044613173388\n",
            "INFO - Running Mean RL Loss: 2816.9625787646946\n",
            "INFO - Running Mean RL Loss: 2816.0568113914587\n",
            "INFO - Running Mean RL Loss: 2814.7595391005407\n",
            "INFO - Running Mean RL Loss: 2811.164013876544\n",
            "INFO - Running Mean RL Loss: 2810.540504614073\n",
            "INFO - Running Mean RL Loss: 2810.2434610909977\n",
            "INFO - Running Mean RL Loss: 2809.494324139489\n",
            "INFO - Running Mean RL Loss: 2808.6687422571135\n",
            "INFO - Running Mean RL Loss: 2806.5670272730167\n",
            "INFO - Running Mean RL Loss: 2808.3065522220595\n",
            "INFO - Running Mean RL Loss: 2808.5726420747123\n",
            "INFO - Running Mean RL Loss: 2807.8230585087053\n",
            "INFO - Running Mean RL Loss: 2807.1572144353354\n",
            "INFO - Running Mean RL Loss: 2804.5234914917924\n",
            "INFO - Running Mean RL Loss: 2802.427625769035\n",
            "INFO - Running Mean RL Loss: 2802.04492605713\n",
            "INFO - Running Mean RL Loss: 2799.1860273731204\n",
            "INFO - Running Mean RL Loss: 2795.5472104747323\n",
            "INFO - Running Mean RL Loss: 2794.108181272429\n",
            "INFO - Running Mean RL Loss: 2793.0057595261555\n",
            "INFO - Running Mean RL Loss: 2791.760602513178\n",
            "INFO - Running Mean RL Loss: 2789.0158791018403\n",
            "INFO - Running Mean RL Loss: 2786.201907953008\n",
            "INFO - Running Mean RL Loss: 2789.4099085583257\n",
            "INFO - Running Mean RL Loss: 2789.5057545283075\n",
            "INFO - Running Mean RL Loss: 2793.646502826619\n",
            "INFO - Running Mean RL Loss: 2791.976192430069\n",
            "INFO - Running Mean RL Loss: 2790.5761559976168\n",
            "INFO - Running Mean RL Loss: 2786.4709338036437\n",
            "INFO - Running Mean RL Loss: 2785.464877930011\n",
            "INFO - Running Mean RL Loss: 2787.597872736512\n",
            "INFO - Running Mean RL Loss: 2789.0294960088013\n",
            "INFO - Running Mean RL Loss: 2789.634920908703\n",
            "INFO - Running Mean RL Loss: 2788.6297547995464\n",
            "INFO - Running Mean RL Loss: 2786.208679773171\n",
            "INFO - Running Mean RL Loss: 2782.420651940571\n",
            "INFO - Running Mean RL Loss: 2779.8926371637885\n",
            "INFO - Running Mean RL Loss: 2778.5924001465023\n",
            "INFO - Running Mean RL Loss: 2779.613598184599\n",
            "INFO - Running Mean RL Loss: 2779.0515899641036\n",
            "INFO - Policy: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with epsilon = 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - Running Mean RL Loss: 2779.9523812450393\n",
            "INFO - Running Mean RL Loss: 2785.5406535454586\n",
            "INFO - Running Mean RL Loss: 2786.9563620817485\n",
            "INFO - Running Mean RL Loss: 2784.439830668082\n",
            "INFO - Running Mean RL Loss: 2783.816649060416\n",
            "INFO - Running Mean RL Loss: 2781.9592888072934\n",
            "INFO - Running Mean RL Loss: 2783.8122523531156\n",
            "INFO - Running Mean RL Loss: 2783.6282472097605\n",
            "INFO - Running Mean RL Loss: 2784.4147395995383\n",
            "INFO - Running Mean RL Loss: 2782.9302560040096\n",
            "INFO - Running Mean RL Loss: 2781.527210969065\n",
            "INFO - Running Mean RL Loss: 2781.8146293056857\n",
            "INFO - Running Mean RL Loss: 2779.5266015933817\n",
            "INFO - Running Mean RL Loss: 2778.725239543504\n",
            "INFO - Running Mean RL Loss: 2776.3497034242628\n",
            "INFO - Running Mean RL Loss: 2779.093891959417\n",
            "INFO - Running Mean RL Loss: 2778.946228961226\n",
            "INFO - Running Mean RL Loss: 2779.8773651471533\n",
            "INFO - Running Mean RL Loss: 2775.967549797431\n",
            "INFO - Running Mean RL Loss: 2774.732444829561\n",
            "INFO - Running Mean RL Loss: 2772.560802543218\n",
            "INFO - Running Mean RL Loss: 2770.4293680880996\n",
            "INFO - Running Mean RL Loss: 2773.9325941151033\n",
            "INFO - Running Mean RL Loss: 2773.7996396781477\n",
            "INFO - Running Mean RL Loss: 2773.079951523424\n",
            "INFO - Running Mean RL Loss: 2773.116400514282\n",
            "INFO - Running Mean RL Loss: 2776.1669384259058\n",
            "INFO - Running Mean RL Loss: 2774.305606342772\n",
            "INFO - Running Mean RL Loss: 2772.019145605968\n",
            "INFO - Running Mean RL Loss: 2773.1614759004983\n",
            "INFO - Running Mean RL Loss: 2772.6692405368544\n",
            "INFO - Running Mean RL Loss: 2769.6670079652017\n",
            "INFO - Running Mean RL Loss: 2766.5092006078694\n",
            "INFO - Running Mean RL Loss: 2768.8286829963417\n",
            "INFO - Running Mean RL Loss: 2770.2049009861203\n",
            "INFO - Running Mean RL Loss: 2769.1909534044667\n",
            "INFO - Running Mean RL Loss: 2766.7182004688575\n",
            "INFO - Running Mean RL Loss: 2764.462847049993\n",
            "INFO - Running Mean RL Loss: 2767.012178800063\n",
            "INFO - Running Mean RL Loss: 2764.508664566965\n",
            "INFO - Running Mean RL Loss: 2764.6303641038116\n",
            "INFO - Running Mean RL Loss: 2764.2583785054017\n",
            "INFO - Running Mean RL Loss: 2763.0927452107\n",
            "INFO - Running Mean RL Loss: 2766.9677779254575\n",
            "INFO - Running Mean RL Loss: 2765.2737773377726\n",
            "INFO - Running Mean RL Loss: 2764.350159731965\n",
            "INFO - Running Mean RL Loss: 2763.0962382755606\n",
            "INFO - Running Mean RL Loss: 2763.6950128779094\n",
            "INFO - Running Mean RL Loss: 2763.4557777878517\n",
            "INFO - Running Mean RL Loss: 2762.7579444693906\n",
            "INFO - Running Mean RL Loss: 2768.2190841942625\n",
            "INFO - Running Mean RL Loss: 2764.772728365376\n",
            "INFO - Running Mean RL Loss: 2762.945699583818\n",
            "INFO - Running Mean RL Loss: 2765.100321720012\n",
            "INFO - Running Mean RL Loss: 2764.285294259152\n",
            "INFO - Running Mean RL Loss: 2763.7648771939175\n",
            "INFO - Running Mean RL Loss: 2762.744601729274\n",
            "INFO - Running Mean RL Loss: 2762.122143837918\n",
            "INFO - Running Mean RL Loss: 2763.919700017007\n",
            "INFO - Running Mean RL Loss: 2764.385454785861\n",
            "INFO - Running Mean RL Loss: 2762.692034071079\n",
            "INFO - Running Mean RL Loss: 2764.2484194351287\n",
            "INFO - Running Mean RL Loss: 2762.9275302494148\n",
            "INFO - Running Mean RL Loss: 2764.270468983642\n",
            "INFO - Running Mean RL Loss: 2768.0955059999287\n",
            "INFO - Running Mean RL Loss: 2766.7982687014037\n",
            "INFO - Running Mean RL Loss: 2765.8741423741135\n",
            "INFO - Running Mean RL Loss: 2762.8498640473817\n",
            "INFO - Running Mean RL Loss: 2763.734701664751\n",
            "INFO - Running Mean RL Loss: 2761.542263998867\n",
            "INFO - Running Mean RL Loss: 2759.0800854748204\n",
            "INFO - Running Mean RL Loss: 2760.28830365837\n",
            "INFO - Running Mean RL Loss: 2757.4326940422134\n",
            "INFO - Running Mean RL Loss: 2755.493007758644\n",
            "INFO - Running Mean RL Loss: 2755.764428000201\n",
            "INFO - Running Mean RL Loss: 2756.6088861778153\n",
            "INFO - Running Mean RL Loss: 2756.094557492697\n",
            "INFO - Running Mean RL Loss: 2754.9510417398988\n",
            "INFO - Running Mean RL Loss: 2754.669303800785\n",
            "INFO - Running Mean RL Loss: 2754.45775759017\n",
            "INFO - Running Mean RL Loss: 2754.986466202144\n",
            "INFO - Running Mean RL Loss: 2753.9332872953914\n",
            "INFO - Running Mean RL Loss: 2753.2848673484973\n",
            "INFO - Running Mean RL Loss: 2752.4796446058835\n",
            "INFO - Running Mean RL Loss: 2749.2577985100793\n",
            "INFO - Running Mean RL Loss: 2748.5626932793725\n",
            "INFO - Running Mean RL Loss: 2746.7302369656495\n",
            "INFO - Running Mean RL Loss: 2746.2980724233234\n",
            "INFO - Running Mean RL Loss: 2746.6432590566374\n",
            "INFO - Running Mean RL Loss: 2748.611976543576\n",
            "INFO - Running Mean RL Loss: 2747.6942988529686\n",
            "INFO - Running Mean RL Loss: 2750.4655332891743\n",
            "INFO - Running Mean RL Loss: 2750.8411390030733\n",
            "INFO - Running Mean RL Loss: 2750.412874264725\n",
            "INFO - Running Mean RL Loss: 2751.040358902678\n",
            "INFO - Running Mean RL Loss: 2752.0180451582696\n",
            "INFO - Running Mean RL Loss: 2753.1198110181963\n",
            "INFO - Running Mean RL Loss: 2751.0190748569516\n",
            "INFO - Running Mean RL Loss: 2754.668845857944\n",
            "INFO - Running Mean RL Loss: 2754.569647802852\n",
            "INFO - Running Mean RL Loss: 2752.2692464786533\n",
            "INFO - Running Mean RL Loss: 2750.5118569432507\n",
            "INFO - Running Mean RL Loss: 2750.7246555955767\n",
            "INFO - Running Mean RL Loss: 2750.2619780552186\n",
            "INFO - Running Mean RL Loss: 2749.778449359172\n",
            "INFO - Running Mean RL Loss: 2747.3370667062395\n",
            "INFO - Running Mean RL Loss: 2748.9219448924905\n",
            "INFO - Running Mean RL Loss: 2749.7428143115603\n",
            "INFO - Running Mean RL Loss: 2748.173194183087\n",
            "INFO - Running Mean RL Loss: 2746.1411556900184\n",
            "INFO - Running Mean RL Loss: 2744.434514930681\n",
            "INFO - Running Mean RL Loss: 2742.413347164117\n",
            "INFO - Running Mean RL Loss: 2743.4200598925268\n",
            "INFO - Running Mean RL Loss: 2742.2969075271653\n",
            "INFO - Running Mean RL Loss: 2740.9407621165074\n",
            "INFO - Running Mean RL Loss: 2742.1195666822528\n",
            "INFO - Running Mean RL Loss: 2741.505474162296\n",
            "INFO - Running Mean RL Loss: 2742.8850392671293\n",
            "INFO - Running Mean RL Loss: 2743.738007321709\n",
            "INFO - Running Mean RL Loss: 2743.623687099358\n",
            "INFO - Running Mean RL Loss: 2743.386188186165\n",
            "INFO - Running Mean RL Loss: 2742.827527004748\n",
            "INFO - Running Mean RL Loss: 2742.668493258556\n",
            "INFO - Running Mean RL Loss: 2745.3380692922124\n",
            "INFO - Running Mean RL Loss: 2745.853744533923\n",
            "INFO - Running Mean RL Loss: 2746.017658350949\n",
            "INFO - Running Mean RL Loss: 2743.3907153722052\n",
            "INFO - Running Mean RL Loss: 2742.0514154862367\n",
            "INFO - Running Mean RL Loss: 2741.1758711709813\n",
            "INFO - Running Mean RL Loss: 2738.927677417374\n",
            "INFO - Running Mean RL Loss: 2740.47446672742\n",
            "INFO - Running Mean RL Loss: 2739.9329817448\n",
            "INFO - Running Mean RL Loss: 2738.3891928988646\n",
            "INFO - Running Mean RL Loss: 2736.9964209628847\n",
            "INFO - Running Mean RL Loss: 2738.4820877676148\n",
            "INFO - Running Mean RL Loss: 2737.649572918182\n",
            "INFO - Running Mean RL Loss: 2736.743900592248\n",
            "INFO - Running Mean RL Loss: 2736.4630663144885\n",
            "INFO - Running Mean RL Loss: 2735.5476379865063\n",
            "INFO - Running Mean RL Loss: 2735.761387965093\n",
            "INFO - Running Mean RL Loss: 2736.2768373833737\n",
            "INFO - Running Mean RL Loss: 2739.7496472625626\n",
            "INFO - Running Mean RL Loss: 2742.1638160087077\n",
            "INFO - Running Mean RL Loss: 2739.807503558057\n",
            "INFO - Running Mean RL Loss: 2740.728641751104\n",
            "INFO - Running Mean RL Loss: 2740.900739427962\n",
            "INFO - Running Mean RL Loss: 2740.6926489414554\n",
            "INFO - Running Mean RL Loss: 2742.7303068625624\n",
            "INFO - Running Mean RL Loss: 2740.6999773979524\n",
            "/content/OCR/Code/Utils/Performance.py:15: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f110b5112eb04161a5e2be1458face8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for seqeval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/seqeval.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './Log/action_length=32_lr_1e-06_reward=normal_slow_start=True/OCR_loss_history_policy_4.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cc1dfa474d46>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mslow_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslow_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-cf11e0aecc77>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(learning_rate, gamma, action_length, epoches, reward, slow_start)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalRlAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_cal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mPlotAgentLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDir_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/OCR/Code/Utils/Logging.py\u001b[0m in \u001b[0;36mPlotAgentLoss\u001b[0;34m(file_path, policy)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mOCR_json_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'/OCR_loss_history_policy_{policy}.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOCR_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloaded_OCR_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Log/action_length=32_lr_1e-06_reward=normal_slow_start=True/OCR_loss_history_policy_4.json'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rate = 1e-6\n",
        "gamma=0.99\n",
        "action_length = 32\n",
        "epoch = 5\n",
        "reward = \"normal\"\n",
        "slow_start = True\n",
        "\n",
        "agent_0, f1_score = main(learning_rate, gamma, action_length, epoch, reward, slow_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuKsv_FFeIuH"
      },
      "outputs": [],
      "source": [
        "print(f\"Experiment 1,test_f1_score: {f1_score} \")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "158b8d46d99744ff861ba9b75e2d6ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f56514be0c4ddf878417a2b5bce4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa591cd9321a46849f98387bb7254737",
            "placeholder": "​",
            "style": "IPY_MODEL_4443bef88fe94250a111c8cfa783108c",
            "value": " 6.33k/? [00:00&lt;00:00, 427kB/s]"
          }
        },
        "4443bef88fe94250a111c8cfa783108c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe04db9d8864182a1cfda5fe58c4077": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea7c3a0cd4c4c12af77b44330550e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89b31b3c6ada4bdd8184764d3f643079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9865a44378a447dea0a9048e3e9f2de5",
            "max": 2471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea7c3a0cd4c4c12af77b44330550e0a",
            "value": 2471
          }
        },
        "9865a44378a447dea0a9048e3e9f2de5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa591cd9321a46849f98387bb7254737": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c889d3bd583645eb8170ac7bd0e225c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7c9a2f98ab42bab9214be9dea32fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c889d3bd583645eb8170ac7bd0e225c4",
            "placeholder": "​",
            "style": "IPY_MODEL_158b8d46d99744ff861ba9b75e2d6ccd",
            "value": "Downloading builder script: "
          }
        },
        "f110b5112eb04161a5e2be1458face8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea7c9a2f98ab42bab9214be9dea32fe3",
              "IPY_MODEL_89b31b3c6ada4bdd8184764d3f643079",
              "IPY_MODEL_15f56514be0c4ddf878417a2b5bce4ba"
            ],
            "layout": "IPY_MODEL_4fe04db9d8864182a1cfda5fe58c4077"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
